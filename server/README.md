# ğŸ¦ LEO Server - Backend API & Execution Engine

## ğŸ“œ Overview

The LEO Server is the **backend API** that powers the **LEO CLI** by processing user requests, generating system commands via **Vertex AI**, and executing them in a **secure and sandboxed environment**. It also manages logging, authentication, and error handling.

This backend supports:  
âœ… **FastAPI-powered REST API**  
âœ… **Google Vertex AI integration** for command generation  
âœ… **Secure execution in isolated Docker/gVisor containers**  
âœ… **Google Cloud SQL (PostgreSQL) for logging execution results**  
âœ… **Google Secret Manager for secure credentials handling**  

---

## ğŸ“‚ Directory Structure

```
server/
â”‚â”€â”€ main.py            # FastAPI entry point (routes & logic)
â”‚â”€â”€ routes.py          # API endpoint definitions
â”‚â”€â”€ vertex_ai.py       # Handles LLM calls to Google Vertex AI
â”‚â”€â”€ execution_engine.py # Secure command execution in Docker/gVisor
â”‚â”€â”€ db.py              # PostgreSQL connection & ORM models
â”‚â”€â”€ models.py          # Data models for logs, execution tracking
â”‚â”€â”€ logging.py         # Sends logs to Cloud Logging
â”‚â”€â”€ security.py        # Handles authentication, permissions
â”‚â”€â”€ secrets.py         # Loads credentials from Google Secret Manager
â”‚â”€â”€ config.py          # Config settings for the API
â”‚â”€â”€ requirements.txt   # Dependencies for FastAPI backend
â”‚â”€â”€ README.md          # Documentation for the server module
```

---

## ğŸ“œ Detailed File Descriptions

### **1ï¸âƒ£ main.py - API Entry Point**
- Initializes **FastAPI application**  
- Mounts API **routes**  
- Configures middleware for **CORS, authentication, and logging**  

ğŸ”¹ **Example Startup Script:**  
```python
from fastapi import FastAPI
from routes import router

app = FastAPI(title="LEO API")

app.include_router(router)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

### **2ï¸âƒ£ routes.py - API Endpoints**
Defines **RESTful API routes** for processing CLI requests.

ğŸ”¹ **Example Endpoints:**  
- `POST /generate-command` â†’ Calls Vertex AI to generate shell commands.  
- `POST /execute` â†’ Runs the generated command in a secure container.  
- `GET /logs` â†’ Retrieves execution logs from the database.  

---

### **3ï¸âƒ£ vertex_ai.py - LLM Integration**
Handles **communication with Google Vertex AI** to generate system commands from natural language prompts.

ğŸ”¹ **Example Call to Vertex AI:**  
```python
from google.cloud import aiplatform

def generate_command(prompt: str):
    response = aiplatform.PredictionServiceClient().predict(...)
    return response.payload.text
```

---

### **4ï¸âƒ£ execution_engine.py - Secure Command Execution**
Executes **system commands in an isolated environment** to prevent security risks.

ğŸ”¹ **Features:**  
âœ… Runs commands in **Docker containers**  
âœ… Uses **gVisor or Firecracker** for **sandboxing**  
âœ… Implements **timeout & resource limits**  

ğŸ”¹ **Example Execution:**  
```python
import subprocess

def execute_command(command: str):
    result = subprocess.run(command, shell=True, capture_output=True)
    return result.stdout.decode()
```

---

### **5ï¸âƒ£ db.py - Database Connection**
Handles connection to **Google Cloud SQL (PostgreSQL)** for **logging executions**.

ğŸ”¹ **Example Connection:**  
```python
from sqlalchemy import create_engine

DATABASE_URL = "postgresql://user:password@host:port/dbname"
engine = create_engine(DATABASE_URL)
```

---

### **6ï¸âƒ£ logging.py - Execution Logs**
Stores logs in **Google Cloud Logging** for monitoring and debugging.

---

### **7ï¸âƒ£ security.py - Authentication & Permissions**
Handles **OAuth, API keys, and user authentication**.

---

## ğŸš€ Getting Started

### **ğŸ“¥ Installation**

```bash
pip install -r requirements.txt
```

### **ğŸš€ Running the API Server**

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“œ License
This project is licensed under the **MIT License**.
